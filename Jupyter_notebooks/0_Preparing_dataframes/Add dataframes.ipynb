{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding orgs, pers, pubs, projs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose which dfs you want to import and add\n",
    "numbers=['3', '3IDR', '3multi', '5multi', '5IDR', '5', '7IDR', '7multi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exporting  the finished df_0 and df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\\\dataframes_to_add/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "number=numbers[0]\n",
    "tot_publications_0 = pd.read_csv(path + number +'publications_0.csv')  \n",
    "tot_projects_0 = pd.read_csv(path + number +'projects_0.csv')  \n",
    "tot_persons_0 = pd.read_csv(path + number +'persons_0.csv')  \n",
    "tot_organisations_0 = pd.read_csv(path + number+'organisations_0.csv') \n",
    "\n",
    "for i in range(1,len(numbers)):\n",
    "    number=numbers[i]\n",
    "    publications_0 = pd.read_csv(path + number+'publications_0.csv')  \n",
    "    projects_0 = pd.read_csv(path + number+'projects_0.csv')  \n",
    "    persons_0 = pd.read_csv(path + number+'persons_0.csv')  \n",
    "    organisations_0 = pd.read_csv(path + number+'organisations_0.csv')\n",
    "    \n",
    "    tot_publications_0 = tot_publications_0.append(publications_0, ignore_index=True)\n",
    "    tot_projects_0 = tot_projects_0.append(projects_0, ignore_index=True)\n",
    "    tot_persons_0 = tot_persons_0.append(persons_0, ignore_index=True)\n",
    "    tot_organisations_0 = tot_organisations_0.append(organisations_0, ignore_index=True)\n",
    "\n",
    "tot_publications_0=tot_publications_0.drop_duplicates()\n",
    "tot_projects_0=tot_projects_0.drop_duplicates()\n",
    "tot_persons_0=tot_persons_0.drop_duplicates()\n",
    "tot_organisations_0=tot_organisations_0.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "number=numbers[0]\n",
    "tot_publications_1 = pd.read_csv(path + number+'publications_1.csv')  \n",
    "tot_projects_1 = pd.read_csv(path + number+'projects_1.csv')  \n",
    "tot_persons_1 = pd.read_csv(path + number+'persons_1.csv')  \n",
    "tot_organisations_1 = pd.read_csv(path + number+'organisations_1.csv') \n",
    "\n",
    "for i in range(1,len(numbers)):\n",
    "    number=numbers[i]\n",
    "    publications_1 = pd.read_csv(path + number+'publications_1.csv')  \n",
    "    projects_1 = pd.read_csv(path + number+'projects_1.csv')  \n",
    "    persons_1 = pd.read_csv(path + number+'persons_1.csv')  \n",
    "    organisations_1 = pd.read_csv(path + number+'organisations_1.csv')\n",
    "    \n",
    "    tot_publications_1 = tot_publications_1.append(publications_1, ignore_index=True)\n",
    "    tot_projects_1 = tot_projects_1.append(projects_1, ignore_index=True)\n",
    "    tot_persons_1 = tot_persons_1.append(persons_1, ignore_index=True)\n",
    "    tot_organisations_1 = tot_organisations_1.append(organisations_1, ignore_index=True)\n",
    "    \n",
    "tot_publications_1=tot_publications_1.drop_duplicates()\n",
    "tot_projects_1=tot_projects_1.drop_duplicates()\n",
    "tot_persons_1=tot_persons_1.drop_duplicates()\n",
    "tot_organisations_1=tot_organisations_1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = tot_publications_0.append(tot_publications_1, ignore_index=True)\n",
    "projects = tot_projects_0.append(tot_projects_1, ignore_index=True)\n",
    "persons = tot_persons_0.append(tot_persons_1, ignore_index=True)\n",
    "organisations = tot_organisations_0.append(tot_organisations_1, ignore_index=True)\n",
    "\n",
    "publications=publications.drop_duplicates(subset=['ID'])\n",
    "projects=projects.drop_duplicates(subset=['ID'])\n",
    "persons=persons.drop_duplicates(subset=['ID'])\n",
    "organisations=organisations.drop_duplicates(subset=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications.to_csv('0publications.csv', index=False)\n",
    "projects.to_csv('0projects.csv', index=False)\n",
    "persons.to_csv('0persons.csv', index=False)\n",
    "organisations.to_csv('0organisations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_publications_0.to_csv('0publications_0.csv', index=False)\n",
    "tot_projects_0.to_csv('0projects_0.csv', index=False)\n",
    "tot_persons_0.to_csv('0persons_0.csv', index=False)\n",
    "tot_organisations_0.to_csv('0organisations_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path= r'C:\\Users\\lucp11051\\PycharmProjects\\idr\\df_maker_input_output/'\n",
    "\n",
    "np.savetxt(path + 'publication_ids.txt', np.array(publications['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'project_ids.txt', np.array(projects['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'person_ids.txt', np.array(persons['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'organisation_ids.txt', np.array(organisations['ID']), fmt= '%s')\n",
    "\n",
    "np.savetxt(path + 'publication_ids_0.txt', np.array(tot_publications_0['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'project_ids_0.txt', np.array(tot_projects_0['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'person_ids_0.txt', np.array(tot_persons_0['ID']), fmt= '%s')\n",
    "np.savetxt(path + 'organisation_ids_0.txt', np.array(tot_organisations_0['ID']), fmt= '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path= r'C:\\Users\\lucp11051\\PycharmProjects\\idr\\df_maker_input_output/'\n",
    "\n",
    "# np.savetxt(path + 'publication_ids.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'project_ids.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'person_ids.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'organisation_ids.txt', np.array([]), fmt= '%s')\n",
    "\n",
    "# np.savetxt(path + 'publication_ids_0.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'project_ids_0.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'person_ids_0.txt', np.array([]), fmt= '%s')\n",
    "# np.savetxt(path + 'organisation_ids_0.txt', np.array([]), fmt= '%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

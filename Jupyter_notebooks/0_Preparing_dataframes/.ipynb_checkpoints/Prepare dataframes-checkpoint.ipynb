{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA FRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose which dfs you want to import\n",
    "number='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages, data and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\lucp11051\\Documents\\Jupyter_notebooks\\0_Preparing_dataframes/'\n",
    "\n",
    "publications_0 = pd.read_csv(path + number+'publications_0.csv')  \n",
    "projects_0 = pd.read_csv(path + number+'projects_0.csv')  \n",
    "persons_0 = pd.read_csv(path + number+'persons_0.csv')  \n",
    "organisations_0 = pd.read_csv(path + number+'organisations_0.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\lucp11051\\Documents\\Jupyter_notebooks\\0_Preparing_dataframes/'\n",
    "\n",
    "publications = pd.read_csv(path + number+'publications.csv')  \n",
    "projects = pd.read_csv(path + number+'projects.csv')  \n",
    "persons = pd.read_csv(path + number+'persons.csv')  \n",
    "organisations = pd.read_csv(path + number+'organisations.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to bring a list of (level 4) disciplines to a list of level 2\n",
    "def bring_to_level_2(list_of_disc):\n",
    "    level_2_list=[]\n",
    "    for disc in list_of_disc:\n",
    "        level_2_list= level_2_list + [disc[:4]]\n",
    "    return level_2_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values \n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    # print list \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function that adds columns to the initial dataframe df_0:\n",
    "# 'Level-2 disciplines '+ entity_string: the level 2 disciplines of a chosen entity\n",
    "# 'Unique level-2 disciplines '+ entity_string: the unique level 2 disciplines of a chosen entity\n",
    "# Example: (df_0, entity_df, entity_string) = (persons,organisations, 'Organisations')\n",
    "def get_related_level2_disciplines(df_0, entity_df, entity_string):\n",
    "    level2_col=[]\n",
    "    for i in range(len(df_0)):\n",
    "        level2=[]\n",
    "        for entity_id in df_0[entity_string][i]:\n",
    "            if len(entity_df[entity_df['ID'] == entity_id]['Level-2 disciplines']) == 0:\n",
    "                entity_level2=[] \n",
    "            else:\n",
    "                entity_level2=entity_df[entity_df['ID'] == entity_id]['Level-2 disciplines'].iloc[0]\n",
    "            level2=level2 + [entity_level2]\n",
    "        level2_col=level2_col+[level2]\n",
    "    df_0['Level-2 disciplines '+ entity_string]=level2_col\n",
    "#     df_0['Unique level-2 disciplines '+ entity_string]=df_0['Level-2 disciplines '+ entity_string].apply(lambda x: unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes a list with (non-unique) codes and gives a discipline vector (np.array)\n",
    "def make_discipline_vector(level2_list, discipline_codes):\n",
    "    disc_vector = np.array([0]*len(discipline_codes))\n",
    "    for i in range(len(discipline_codes)):\n",
    "        disc_vector[i]=level2_list.count(discipline_codes[i])\n",
    "        \n",
    "    if sum(disc_vector)>0:\n",
    "        normalized_vector=disc_vector/sum(disc_vector)\n",
    "    else:\n",
    "        normalized_vector=disc_vector\n",
    "    return normalized_vector\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_months(datetime_end, datetime_start):\n",
    "    time_difference = relativedelta(datetime_end, datetime_start)\n",
    "    difference_in_years = time_difference.years\n",
    "    if time_difference.days > 14:\n",
    "        extra_month = 1\n",
    "    else:\n",
    "        extra_month = 0\n",
    "    rest_months = time_difference.months +extra_month\n",
    "    difference_in_months = difference_in_years*12 + rest_months\n",
    "    \n",
    "    return difference_in_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(date_str):\n",
    "    if 'Z' in date_str:\n",
    "        date_str=date_str.replace('Z','')\n",
    "    return datetime.strptime(date_str, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merge_aliases(df, entity):\n",
    "    new_df=df.copy()\n",
    "    for i in range(df.shape[0]):        \n",
    "        all_ids = [df['ID'][i]] + df['Alias'][i]\n",
    "        alias_df = df[df['ID'].isin(all_ids)]\n",
    "        if entity == 'projects':\n",
    "            new_df.loc[i,'Disciplines'] = str(alias_df['Disciplines'].sum())\n",
    "            new_df.loc[i,'Persons'] = str(unique(alias_df['Persons'].sum()))\n",
    "            new_df.loc[i,'Organisations'] = str(alias_df['Organisations'].sum())\n",
    "            new_df.loc[i,'Publications'] = str(unique(alias_df['Publications'].sum()))\n",
    "            new_df.loc[i,'Duration'] = alias_df['Duration'].mean()\n",
    "        elif entity == 'persons':\n",
    "            new_df.loc[i,'Disciplines'] = str(alias_df['Disciplines'].sum())\n",
    "            new_df.loc[i,'Organisations'] = str(unique(alias_df['Organisations'].sum()))\n",
    "            new_df.loc[i,'Publications'] = str(unique(alias_df['Publications'].sum()))\n",
    "            new_df.loc[i,'Projects'] = str(unique(alias_df['Projects'].sum()))\n",
    "        elif entity == 'publications':\n",
    "            new_df.loc[i,'Disciplines'] = str(alias_df['Disciplines'].sum())\n",
    "            new_df.loc[i,'Persons'] = str(unique(alias_df['Persons'].sum()))               \n",
    "            new_df.loc[i,'Size'] = alias_df['Size'].mean()\n",
    "            new_df.loc[i,'Disciplines WoS'] = str(alias_df['Disciplines WoS'].sum())\n",
    "            new_df.loc[i,'Disciplines vabb'] = str(alias_df['Disciplines vabb'].sum())\n",
    "            new_df.loc[i,'WoS ID'] = str(alias_df['WoS ID'].sum())\n",
    "            new_df.loc[i,'vabb ID'] = str(alias_df['vabb ID'].sum())\n",
    "        else:\n",
    "            raise Exception('Entity should be either \\'projects\\', \\'persons\\' or \\'publications\\'.')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bookcomponent(list_of_pubs):\n",
    "    clean_list=[]\n",
    "    for pub_id in list_of_pubs:\n",
    "        pub_id = pub_id.replace('book-component:', '')\n",
    "        clean_list=clean_list+[pub_id]\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 percent of projects is valid.\n",
      "100.0 percent of projects_0 is valid.\n"
     ]
    }
   ],
   "source": [
    "# delete invalid and duplicate projects\n",
    "\n",
    "projects_total=projects.shape[0]\n",
    "projects=projects.drop(projects[projects.Name == 'ERROR'].index)\n",
    "projects_valid=projects.shape[0]\n",
    "projects.drop_duplicates(subset=['ID'])\n",
    "projects.index=range(projects_valid)\n",
    "\n",
    "print(projects_valid/projects_total *100, 'percent of projects is valid.')\n",
    "\n",
    "projects_0_total=projects_0.shape[0]\n",
    "projects_0=projects_0.drop(projects_0[projects_0.Name == 'ERROR'].index)\n",
    "projects_0_valid=projects_0.shape[0]\n",
    "projects_0.drop_duplicates(subset=['ID'])\n",
    "projects_0.index=range(projects_0_valid)\n",
    "\n",
    "print(projects_0_valid/projects_0_total *100, 'percent of projects_0 is valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# merge aliases, add level2 disciplines, literal_eval, ...\n",
    "\n",
    "projects['Disciplines'] = projects['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "projects['Persons'] = projects['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects['Organisations'] = projects['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects['Publications'] = projects['Publications'].apply(lambda x: literal_eval(x))\n",
    "projects['Alias'] = projects['Alias'].apply(lambda x: literal_eval(x))\n",
    "projects['Start']=projects['Start'].apply(lambda x: string_to_datetime(x))\n",
    "projects['End']=projects['End'].apply(lambda x: string_to_datetime(x))\n",
    "length=[]\n",
    "for i in range(projects.shape[0]):\n",
    "    length=length + [difference_in_months(projects['End'][i],projects['Start'][i])]\n",
    "projects['Duration']=length\n",
    "projects = merge_aliases(projects, 'projects')\n",
    "\n",
    "projects['Disciplines'] = projects['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "projects['Persons'] = projects['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects['Organisations'] = projects['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects['Publications'] = projects['Publications'].apply(lambda x: unique(remove_bookcomponent(literal_eval(x))))\n",
    "projects['Level-2 disciplines']=projects['Disciplines'].apply(lambda x: bring_to_level_2(x))\n",
    "projects['Size']=projects['Persons'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# merge aliases, add level2 disciplines, literal_eval, ...\n",
    "projects_0['Disciplines'] = projects_0['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "projects_0['Persons'] = projects_0['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects_0['Organisations'] = projects_0['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects_0['Publications'] = projects_0['Publications'].apply(lambda x: literal_eval(x))\n",
    "projects_0['Alias'] = projects_0['Alias'].apply(lambda x: literal_eval(x))\n",
    "projects_0['Start']=projects_0['Start'].apply(lambda x: string_to_datetime(x))\n",
    "projects_0['End']=projects_0['End'].apply(lambda x: string_to_datetime(x))\n",
    "length=[]\n",
    "for i in range(projects_0.shape[0]):\n",
    "    length=length + [difference_in_months(projects_0['End'][i],projects_0['Start'][i])]\n",
    "projects_0['Duration']=length\n",
    "projects_0 = merge_aliases(projects_0, 'projects')\n",
    "\n",
    "projects_0['Disciplines'] = projects_0['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "projects_0['Persons'] = projects_0['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects_0['Organisations'] = projects_0['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "projects_0['Publications'] = projects_0['Publications'].apply(lambda x: unique(remove_bookcomponent(literal_eval(x))))\n",
    "projects_0['Level-2 disciplines']=projects_0['Disciplines'].apply(lambda x: bring_to_level_2(x))\n",
    "projects_0['Size']=projects_0['Persons'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 percent of persons is valid.\n",
      "100.0 percent of persons_0 is valid.\n"
     ]
    }
   ],
   "source": [
    "# delete invalid and duplicate persons\n",
    "\n",
    "persons_total=persons.shape[0]\n",
    "persons=persons.drop(persons[persons.Name == 'ERROR'].index)\n",
    "persons_valid=persons.shape[0]\n",
    "persons.drop_duplicates(subset=['ID'])\n",
    "persons.index=range(persons_valid)\n",
    "\n",
    "print(persons_valid/persons_total *100, 'percent of persons is valid.')\n",
    "\n",
    "persons_0_total=persons_0.shape[0]\n",
    "persons_0=persons_0.drop(persons_0[persons_0.Name == 'ERROR'].index)\n",
    "persons_0_valid=persons_0.shape[0]\n",
    "persons_0.drop_duplicates(subset=['ID'])\n",
    "persons_0.index=range(persons_0_valid)\n",
    "\n",
    "print(persons_0_valid/persons_0_total *100, 'percent of persons_0 is valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge aliases, add level2 disciplines, literal_eval, ...\n",
    "persons['Disciplines'] = persons['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "persons['Projects'] = persons['Projects'].apply(lambda x: literal_eval(x))\n",
    "persons['Organisations'] = persons['Organisations'].apply(lambda x: literal_eval(x))\n",
    "persons['Publications'] = persons['Publications'].apply(lambda x: literal_eval(x))\n",
    "persons['Alias'] = persons['Alias'].apply(lambda x: literal_eval(x))\n",
    "persons = merge_aliases(persons, 'persons')\n",
    "persons['Disciplines'] = persons['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "persons['Projects'] = persons['Projects'].apply(lambda x: unique(literal_eval(x)))\n",
    "persons['Organisations'] = persons['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "persons['Publications'] = persons['Publications'].apply(lambda x: unique(remove_bookcomponent(literal_eval(x))))\n",
    "persons['Level-2 disciplines']=persons['Disciplines'].apply(lambda x: bring_to_level_2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge aliases, add level2 disciplines, literal_eval, ...\n",
    "persons_0['Disciplines'] = persons_0['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "persons_0['Projects'] = persons_0['Projects'].apply(lambda x: literal_eval(x))\n",
    "persons_0['Organisations'] = persons_0['Organisations'].apply(lambda x: literal_eval(x))\n",
    "persons_0['Publications'] = persons_0['Publications'].apply(lambda x: literal_eval(x))\n",
    "persons_0['Alias'] = persons_0['Alias'].apply(lambda x: literal_eval(x))\n",
    "persons_0 = merge_aliases(persons_0, 'persons')\n",
    "persons_0['Disciplines'] = persons_0['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "persons_0['Projects'] = persons_0['Projects'].apply(lambda x: unique(literal_eval(x)))\n",
    "persons_0['Organisations'] = persons_0['Organisations'].apply(lambda x: unique(literal_eval(x)))\n",
    "persons_0['Publications'] = persons_0['Publications'].apply(lambda x: unique(remove_bookcomponent(literal_eval(x))))\n",
    "persons_0['Level-2 disciplines']=persons_0['Disciplines'].apply(lambda x: bring_to_level_2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.12018489984591 percent of publications is valid.\n"
     ]
    }
   ],
   "source": [
    "# delete invalid and duplicate publications\n",
    "\n",
    "publications_total=publications.shape[0]\n",
    "publications=publications.drop(publications[publications.Name == 'ERROR'].index)\n",
    "publications_valid=publications.shape[0]\n",
    "publications.drop_duplicates(subset=['ID'])\n",
    "publications.index=range(publications_valid)\n",
    "\n",
    "print(publications_valid/publications_total *100, 'percent of publications is valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge aliases, add level2 disciplines, literal_eval, ...\n",
    "publications['Size'] = publications['Size'].apply(lambda x: max(1,literal_eval(x)))\n",
    "publications['WoS ID'] = publications['WoS ID'].apply(lambda x: literal_eval(x))\n",
    "publications['vabb ID'] = publications['vabb ID'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines WoS'] = publications['Disciplines WoS'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines vabb'] = publications['Disciplines vabb'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines'] = publications['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "publications['Persons'] = publications['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "publications['Alias'] = publications['Alias'].apply(lambda x: literal_eval(x))\n",
    "publications=merge_aliases(publications, 'publications')\n",
    "publications['WoS ID'] = publications['WoS ID'].apply(lambda x: literal_eval(x))\n",
    "publications['vabb ID'] = publications['vabb ID'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines WoS'] = publications['Disciplines WoS'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines vabb'] = publications['Disciplines vabb'].apply(lambda x: literal_eval(x))\n",
    "publications['Disciplines'] = publications['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "publications['Persons'] = publications['Persons'].apply(lambda x: unique(literal_eval(x)))\n",
    "publications['Level-2 disciplines']=publications['Disciplines'].apply(lambda x: bring_to_level_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 percent of organisations is valid.\n"
     ]
    }
   ],
   "source": [
    "# delete invalid and duplicate organisations\n",
    "\n",
    "organisations_total=organisations.shape[0]\n",
    "organisations=organisations.drop(organisations[organisations.Name == 'ERROR'].index)\n",
    "organisations_valid=organisations.shape[0]\n",
    "organisations.drop_duplicates(subset=['ID'])\n",
    "organisations.index=range(organisations_valid)\n",
    "\n",
    "print(organisations_valid/organisations_total *100, 'percent of organisations is valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "organisations['Disciplines'] = organisations['Disciplines'].apply(lambda x: literal_eval(x))\n",
    "organisations['Level-2 disciplines']=organisations['Disciplines'].apply(lambda x: bring_to_level_2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
